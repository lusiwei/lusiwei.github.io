<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-02-27T12:52:04.908Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>John Doe</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2019/02/27/Docker%E5%AE%89%E8%A3%85FastDFS/"/>
    <id>http://yoursite.com/2019/02/27/Docker安装FastDFS/</id>
    <published>2019-02-27T12:22:33.262Z</published>
    <updated>2019-02-27T12:52:04.908Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Docker-安装FastDFS"><a href="#Docker-安装FastDFS" class="headerlink" title="Docker 安装FastDFS"></a>Docker 安装FastDFS</h3><ol><li><p>下载docker</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install docker</span><br></pre></td></tr></table></figure></li><li><p>拉取镜像</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull morunchang/fastdfs</span><br></pre></td></tr></table></figure></li><li><p>启动tracker</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name &lt;tracker_name&gt; --net=host morunchang/fastdfs sh tracker.sh</span><br></pre></td></tr></table></figure><p>各个参数含义：</p><ul><li>-d : 后台运行容器，并返回容器ID</li><li>–name : 为容器指定一个名称</li><li>–net ： 指定容器的网络连接类型，支持 bridge/host/none/container: 四种类型</li></ul><p>参考链接：<a href="http://www.runoob.com/docker/docker-run-command.html" target="_blank" rel="noopener">http://www.runoob.com/docker/docker-run-command.html</a></p></li><li><p>启动storage</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name storage \</span><br><span class="line">--net=host \</span><br><span class="line">-e TRACKER_IP=&lt;your tracker server address&gt;:22122 \</span><br><span class="line">-e GROUP_NAME=&lt;group name&gt; \</span><br><span class="line">morunchang/fastdfs sh storage.sh</span><br></pre></td></tr></table></figure><ul><li>\ 为命令行中换行符</li><li>-e: 设置环境变量</li><li>这步需要设置tracker_ip:本机ip地址和group_name</li></ul></li><li><p>查看容器信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker ps</span><br></pre></td></tr></table></figure></li><li><p>进入容器内部</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it storage /bin/bash</span><br></pre></td></tr></table></figure><ul><li>exec : 在运行的容器中执行命令</li><li>-i: 即使没有附加也保持STDIN 打开</li><li>-t: 分配一个伪终端</li></ul></li><li><p>用vim编辑nginx配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /data/nginx/conf/nginx.conf</span><br></pre></td></tr></table></figure></li><li><p>在server里添加如下内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">location /&lt;group1&gt;/M00 &#123;</span><br><span class="line">   proxy_next_upstream http_502 http_504 error timeout invalid_header;</span><br><span class="line">     proxy_cache http-cache;</span><br><span class="line">     proxy_cache_valid  200 304 12h;</span><br><span class="line">     proxy_cache_key $uri$is_args$args;</span><br><span class="line">     proxy_pass http://fdfs_group1;</span><br><span class="line">     expires 30d;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><ul><li>&lt;&gt;里面的内容是你在第四步设置的需要保持一致，其他地方不用修改</li></ul></li><li><p>退出伪终端</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">exit</span><br></pre></td></tr></table></figure></li><li><p>重启storage服务</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker restart storage</span><br></pre></td></tr></table></figure></li><li><p>完成环境的搭建</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Docker-安装FastDFS&quot;&gt;&lt;a href=&quot;#Docker-安装FastDFS&quot; class=&quot;headerlink&quot; title=&quot;Docker 安装FastDFS&quot;&gt;&lt;/a&gt;Docker 安装FastDFS&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;下载doc
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2019/02/23/%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93/"/>
    <id>http://yoursite.com/2019/02/23/项目总结/</id>
    <published>2019-02-23T07:03:06.040Z</published>
    <updated>2019-02-23T12:45:48.959Z</updated>
    
    <content type="html"><![CDATA[<h2 id="项目总结"><a href="#项目总结" class="headerlink" title="项目总结"></a>项目总结</h2><h4 id="权限项目"><a href="#权限项目" class="headerlink" title="权限项目"></a>权限项目</h4><p>我主要在项目中完成了权限模块，整个模块的设计采用RBAC模型，权限控制采用粗粒度，根据用户，获取该用户的角色，根据角色获得相应的权限，权限的具体控制是通过权限表的url拦截实现</p><h5 id="表的设计："><a href="#表的设计：" class="headerlink" title="表的设计："></a>表的设计：</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">graph TD</span><br><span class="line">A(部门表dept) -.-|一对多| B(用户表)</span><br><span class="line">B -.- |多对多| C(角色表)</span><br><span class="line">C-.-|多对多|权限表</span><br><span class="line">日志表</span><br></pre></td></tr></table></figure><p>用户表和角色表之间有一个中间表，角色表和权限表的有一个中间表</p><p><strong>日志表</strong>：包含操作前及操作后，是否能还原，操作人四个核心字段，主要是为了误操作的恢复，以及记录每个操作的操作者，责任落实到人</p><p><strong>权限表</strong>：主要描述了具体的某个权限，以及该操作权限 属于哪个模块，还有最重要的权限操作与url的对应关系</p><h5 id="核心实现功能"><a href="#核心实现功能" class="headerlink" title="核心实现功能"></a>核心实现功能</h5><ol><li><p>通过mail完成邮件的发送</p><p>防止成为垃圾邮件，披上outlook的马甲：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">message.addHeader(<span class="string">"X-Mailer"</span>,<span class="string">"MIcrosoft Outlook Express 6.00.2900.2869"</span>)</span><br></pre></td></tr></table></figure></li><li><p>通过过滤器，cookie及session技术完成用户的登陆拦截，自动登陆，记住密码等功能，   domain path,持久化过期时间maxAge的设置 </p><ul><li>domain表示的是cookie所在的域，默认为请求的地址，如网址为<figure class="highlight plain"><figcaption><span>```t1.test.com```，域B为``` t2.test.com```，那么在域A生产一个令域A和域B都能访问的cookie就要将该cookie的domain设置为```.test.com```；如果要在域A生产一个令域A不能访问而域B能访问的cookie就要将该cookie的domain设置为```t2.test.com```.</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line">   * path表示cookie所在的目录，asp.net默认为/，就是根目录。在同一个服务器上有目录如下：```/test/```,```/test/cd/```,```/test/dd/```，现设一个cookie1的path为```/test/```，cookie2的path为```/test/cd/```，那么test下的所有页面都可以访问到cookie1，而```/test/```和```/test/dd/```的子页面不能访问**cookie2**。这是因为cookie能让其path路径下的页面访问</span><br><span class="line"></span><br><span class="line">3. 通过ThreadLocal 线程副本将用户信息传递到业务层，完成操作的记录(记得在拦截器的afterCompletion中释放ThreadLocal资源)</span><br><span class="line"></span><br><span class="line">4. 通过hibernate-validator 工具，完成校验工具类，完成对参数的校验</span><br><span class="line"></span><br><span class="line">5. 完成拦截器对用户url的拦截，用户的权限缓存到redis中，在拦截器的preHandle中通过request.getRequestUri 取出用户的url，与redis中的进行比对，判断有无权限</span><br><span class="line"></span><br><span class="line">6. 完成jedisUtil，jsonUtil ,ThreadLocalUtil 等工具类的封装</span><br><span class="line"></span><br><span class="line">7. 通过mybatis的翻页插件完成翻页</span><br><span class="line"></span><br><span class="line">8. 完成角色，用户，权限模块增删改及树结构翻页条件查询等接口的开发</span><br><span class="line"></span><br><span class="line">9. 完成操作记录及还原接口的开发</span><br><span class="line"></span><br><span class="line">10. 完成项目的统一异常处理（SpringMvc同意异常处理）</span><br><span class="line"></span><br><span class="line">#### 小商城项目</span><br><span class="line"></span><br><span class="line">Cart:购物车表</span><br><span class="line"></span><br><span class="line">![img](file:///C:\Users\lsw\AppData\Local\Temp\ksohtml11952\wps1.jpg) </span><br><span class="line"></span><br><span class="line">商品分类:(树结构)</span><br><span class="line"></span><br><span class="line">![img](file:///C:\Users\lsw\AppData\Local\Temp\ksohtml11952\wps2.jpg) </span><br><span class="line"></span><br><span class="line">商品表:</span><br><span class="line"></span><br><span class="line">![img](file:///C:\Users\lsw\AppData\Local\Temp\ksohtml11952\wps3.jpg) </span><br><span class="line"></span><br><span class="line">订单表:</span><br><span class="line"></span><br><span class="line">![img](file:///C:\Users\lsw\AppData\Local\Temp\ksohtml11952\wps4.jpg) </span><br><span class="line"></span><br><span class="line">订单项表:</span><br><span class="line"></span><br><span class="line">![img](file:///C:\Users\lsw\AppData\Local\Temp\ksohtml11952\wps5.jpg) </span><br><span class="line"></span><br><span class="line">支付表:</span><br><span class="line"></span><br><span class="line">![img](file:///C:\Users\lsw\AppData\Local\Temp\ksohtml11952\wps6.jpg) </span><br><span class="line"></span><br><span class="line">用户表:</span><br><span class="line"></span><br><span class="line">![img](file:///C:\Users\lsw\AppData\Local\Temp\ksohtml11952\wps7.jpg) </span><br><span class="line"></span><br><span class="line">收件表:</span><br><span class="line"></span><br><span class="line">![img](file:///C:\Users\lsw\AppData\Local\Temp\ksohtml11952\wps8.jpg) </span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">##### 完成功能:</span><br><span class="line"></span><br><span class="line">1. 完成商品图片的fastdfs存储</span><br><span class="line"></span><br><span class="line">   FastDFS：（必须看）不用去看vsftpd了</span><br><span class="line"></span><br><span class="line">   &lt;https://blog.csdn.net/zhengzhaoyang122/article/details/82782604&gt;</span><br><span class="line"></span><br><span class="line">2. 完成购物车模块（商品价格加入后商品价格改变情况，购物车与订单的价格按照加入的时候算）</span><br><span class="line"></span><br><span class="line">   * 每个购物车项对应一个商品，主要是商品数量与商品单价存储，最后在根据这两个算出总价格，避免精度丢失采用bigDecimal高精度</span><br><span class="line"></span><br><span class="line">   * 商品库存，采用加入后就减少库存</span><br><span class="line"></span><br><span class="line">   * 通过定时任务完成购物车的清空（springScheduled需要说出来）cron表达式需要掌握</span><br><span class="line"></span><br><span class="line">     ```java</span><br><span class="line">     @Component</span><br><span class="line">     public class TimerWork&#123;</span><br><span class="line">         @Autowired</span><br><span class="line">         private OrderService orderService;</span><br><span class="line">         @Scheduled(cron=&quot;0/30 * * * * ?&quot;)</span><br><span class="line">     &#125;</span><br></pre></td></tr></table></figure></li></ul></li></ol><ul><li><p>购物车项</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Setter</span></span><br><span class="line"><span class="meta">@Getter</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CartVo</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> List&lt;ProductVo&gt; productVoList;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">boolean</span> allChecked;</span><br><span class="line">    <span class="keyword">private</span> BigDecimal cartTotalPrice;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><ol start="3"><li><p>完成订单模块</p><p>表信息:</p><ul><li><p>user_id:关联用户</p></li><li><p>订单id（未采用分库分表以及mysql集群，就工具类生成）</p></li><li><p>Shippingid:关联收件信息</p></li><li><p>Payment:付款金额</p></li><li><p>Pay_type：采用的支付宝</p></li><li><p>Status订单状态</p></li><li><p>剩下的就是记录时间的字段</p></li></ul><p>订单项:</p><ul><li>订单与订单项通过订单项中的orderNo来关联订单</li></ul><p>包含核心信息:</p><ul><li>商品数量，单价(数量与单价设计跟购物车相同，生成订单后直接减少库存，价格以当时加入为准，后面变化价格不影响)，订单项总价格，以及商品的图片名称等信息</li></ul></li><li><p>完成订单的支付功能（流程必须说清楚，如果问细了就说有点久了现在只能说出大概流程）</p><p>采用支付宝当面付</p><blockquote><p>当面付的简单流程:通过沙箱测试，通过下载支付宝官方的sdk、api</p><p>修改配置信息(商家id、密钥、私钥、公钥等)</p><p>首先在用户点击支付订单的时候通过支付宝api及我们自己文件上传完成二维码生成及展示(fastDFS,nginx反向代理访问)，用户扫描完成支付，支付会自动调用callback回调方法,又对里面订单id、公钥、总价格等等完成验签，成功后完成订单状态修改</p></blockquote></li><li><p>完成nginx与tomcat集群搭建</p><p>一定需要看看，不需要去操作，需要记住大概步骤</p><p><a href="https://www.cnblogs.com/machanghai/p/5957086.html" target="_blank" rel="noopener">https://www.cnblogs.com/machanghai/p/5957086.html</a></p><p>a) 利用nginx完成tomcat集群完成负载均衡</p><p>b) 集群：例如多台tomcat服务器作用于同一个功能，这就叫服务器集群</p><p>c) 分布式:多台tomcat服务器，运行多个功能，就叫分布式</p></li><li><p>完成集群下的单点登录（redis加cookie这个没压力吧）</p><ul><li><p>Redis、cookie完成单点登录</p></li><li><p>Redis：key是一个随机不重复的字符串</p></li><li><p>Value：就是用户的登录信息</p></li><li><p>Cookie：虽然是集群 但是用户都是一个浏览器所以cookie是可以传递</p></li><li><p>Httponly：防攻击</p></li><li><p>Domain:nginx代理 域名是相同</p></li><li><p>Path:/</p></li></ul></li><li><p>完成定时订单，与购物车的取消</p><ul><li><p>定时任务就是springschedule几个注解，扫描一下包就搞定了</p></li><li><p>通过分布式锁避免多tomcat下重复操作（重点撒，必须掌握，先看一遍后面还会讲）</p></li><li><p>取消订单，完成商品数量的增加</p></li></ul></li><li><p>所有接口采用restful风格设计，swagger生成文档</p><ul><li><p>Restful风格的注解必须掌握撒</p><ol><li>@GetMapping</li><li>@postMapping</li><li>@PutMapping</li><li>@DeleteMapping</li></ol></li></ul><p>b) Restful风格实现的@pathvarible必须掌握</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;项目总结&quot;&gt;&lt;a href=&quot;#项目总结&quot; class=&quot;headerlink&quot; title=&quot;项目总结&quot;&gt;&lt;/a&gt;项目总结&lt;/h2&gt;&lt;h4 id=&quot;权限项目&quot;&gt;&lt;a href=&quot;#权限项目&quot; class=&quot;headerlink&quot; title=&quot;权限项目&quot;&gt;&lt;/a
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2019/02/23/3-1%20%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9E%B6%E6%9E%84/"/>
    <id>http://yoursite.com/2019/02/23/3-1 数据库架构/</id>
    <published>2019-02-22T16:10:57.792Z</published>
    <updated>2019-02-20T02:32:08.318Z</updated>
    
    <content type="html"><![CDATA[<h3 id="3-1-数据库架构"><a href="#3-1-数据库架构" class="headerlink" title="3-1 数据库架构"></a>3-1 数据库架构</h3><ol><li>如何设计一个关系型数据库？<ul><li>存储模块（文件系统）</li><li>程序实例<ul><li>存储管理</li><li>缓存机制</li><li>SQL解析</li><li>日志管理</li><li>权限划分</li><li>容灾机制</li><li>索引管理</li><li>锁管理</li></ul></li></ul></li><li>为什么要使用索引？<ul><li>快速查询数据</li></ul></li><li>什么样的信息能成为索引？<ul><li>主键，唯一键以及普通键</li></ul></li><li>索引的数据结构？<ul><li>生成索引，建立二叉查找树进行二分查找</li><li>生成索引，建立B-Tree 结构进行查找</li><li>生成索引，建立B+=Tree 结构进行查找</li><li>生成索引，建立Hash结构进行查找</li></ul></li><li>密集索引和稀疏索引的区别？<ul><li>密集索引文件众的每一个搜索码值都对应一个索引值</li><li>稀疏索引文件只为索引码的某些值建立索引项</li></ul></li><li>InnoDB<ul><li>若一个主键被定义，则该主键则作为密集索引</li><li>若没有主键被定义，该表的第一个唯一非空索引则作为密集索引</li><li>若不满足以上条件，innodb内部会生成一个隐藏主键（密集索引）</li><li>非主键索引存储相关键位和其对应的主键值</li></ul></li><li>如何定位并优化慢查询sql？<ul><li>根据慢查询日志定位慢查询sql</li><li>使用explain等工具分析sql</li><li>修改sql或尽量让sql走索引</li></ul></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;3-1-数据库架构&quot;&gt;&lt;a href=&quot;#3-1-数据库架构&quot; class=&quot;headerlink&quot; title=&quot;3-1 数据库架构&quot;&gt;&lt;/a&gt;3-1 数据库架构&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;如何设计一个关系型数据库？&lt;ul&gt;
&lt;li&gt;存储模块（文件系统）&lt;/li
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2019/02/23/redis%20%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93/"/>
    <id>http://yoursite.com/2019/02/23/redis 面试题总结/</id>
    <published>2019-02-22T16:10:57.780Z</published>
    <updated>2019-02-23T07:03:22.465Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-为什么使用Redis"><a href="#1-为什么使用Redis" class="headerlink" title="1. 为什么使用Redis?"></a>1. 为什么使用Redis?</h3><p>​    主要是从两个角度去考虑:<strong>性能</strong>和<strong>并发</strong>。当然，Redis还具备可以做分布式锁等其他功能，但是如果只是为了分布式锁这些其他功能，完全还有其他中间件(如Zookpeer等)代替,并不是非要使用Redis,因此,这个问题主要从性能和并发两个角度去答。</p><ul><li><p>性能</p><p>我们在碰到需要执行耗时特别久，且结果不频繁变动的 SQL，就特别适合将运行结果放入缓存这样，后面的请求就去缓存中读取，使得请求能够<strong>迅速响应</strong>。</p></li><li><p>并发</p><p>在大并发的情况下，所有的请求直接访问数据库，数据库会出现连接异常。这个时候，就需要使用redis做一个缓冲操作，让请求先访问到 Redis，而不是直接访问数据库。</p></li></ul><h3 id="2．使用redis有什么缺点或者说redis常见项目问题"><a href="#2．使用redis有什么缺点或者说redis常见项目问题" class="headerlink" title="2．使用redis有什么缺点或者说redis常见项目问题"></a>2．使用redis有什么缺点或者说redis常见项目问题</h3><ul><li>缓存和数据库双写一致性问题</li><li>缓存雪崩问题</li><li>缓存击穿问题</li><li>缓存的并发竞争问题</li></ul><h3 id="3．单线程的redis为什么这么快"><a href="#3．单线程的redis为什么这么快" class="headerlink" title="3．单线程的redis为什么这么快"></a>3．单线程的redis为什么这么快</h3><ul><li>纯内存操作,执行效率高</li><li>数据结构简单，对数据的操作也简单</li><li>单线程操作，避免了频繁的上下文切换</li><li>采用了多路I/O复用模型，非阻塞IO</li></ul><h3 id="4-Redis的数据类型，以及每种数据类型的使用场景"><a href="#4-Redis的数据类型，以及每种数据类型的使用场景" class="headerlink" title="4. Redis的数据类型，以及每种数据类型的使用场景"></a>4. Redis的数据类型，以及每种数据类型的使用场景</h3><ul><li><p>String<br>这个其实没啥好说的，最常规的set/get操作，value可以是String也可以是数字。一般做一些复杂的计数功能的缓存。</p></li><li><p>hash<br>这里value存放的是结构化的对象，比较方便的就是操作其中的某个字段。在做单点登录的时候，就是用这种数据结构存储用户信息，以cookieId作为key，设置30分钟为缓存过期时间，能很好的模拟出类似session的效果。</p></li><li><p>list<br>使用链表的数据结构，可以做简单的消息队列的功能。另外还有一个就是，可以利用lrange命令，做基于redis的分页功能，性能极佳，用户体验好。</p><ul><li>我们可以利用lists来实现一个消息队列，而且可以确保先后顺序，不必像MySQL那样还需要通过ORDER BY来进行排序。<ul><li>利用LRANGE还可以很方便的实现分页的功能。</li><li>在博客系统中，每片博文的评论也可以存入一个单独的list中</li></ul></li></ul></li><li><p>set<br>因为set堆放的是一堆不重复值的集合。所以可以做全局去重的功能。为什么不用JVM自带的Set进行去重？因为我们的系统一般都是集群部署，使用JVM自带的Set，比较麻烦，难道为了一个做一个全局去重，再起一个公共服务，太麻烦了。另外，就是利用交集、并集、差集等操作，可以计算共同喜好，全部的喜好，自己独有的喜好等功能。</p><blockquote><p>QQ有一个社交功能叫做“好友标签”，大家可以给你的好友贴标签，比如“大美女”、“土豪”、“欧巴”等等，这时就可以使用redis的集合来实现，把每一个用户的标签都存储在一个集合之中</p></blockquote></li><li><p>sorted set<br>sorted set多了一个权重参数score,集合中的元素能够按score进行排列。可以做排行榜应用，取TOP N操作。可以做范围查找。</p></li></ul><h3 id="5-Redis的过期策略以及内存淘汰机制"><a href="#5-Redis的过期策略以及内存淘汰机制" class="headerlink" title="5. Redis的过期策略以及内存淘汰机制"></a><strong>5. Redis的过期策略以及内存淘汰机制</strong></h3><ul><li><p>分析</p><p> 这个问题其实相当重要，到底redis有没用到家，这个问题就可以看出来。比如你redis只能存5G数据，可是你写了10G，那会删5G的数据。怎么删的，这个问题思考过么？还有，你的数据已经设置了过期时间，但是时间到了，内存占用率还是比较高，有思考过原因么?</p></li><li><p>回答:<br>redis采用的是定期删除+惰性删除策略。</p><ul><li><p><strong>为什么不用定时删除策略?</strong></p><p>定时删除,用一个定时器来负责监视key,过期则自动删除。虽然内存及时释放，但是十分消耗CPU资源。在大并发请求下，CPU要将时间应用在处理请求，而不是删除key,因此没有采用这一策略.</p></li><li><p><strong>定期删除+惰性删除是如何工作的呢?</strong></p><p>定期删除，Redis默认每个100ms检查，是否有过期的key,有过期key则删除。需要说明的是，Redis不是每个100ms将所有的key检查一次，而是随机抽取进行检查(如果每隔100ms,全部key进行检查，Redis岂不是卡死)。因此，如果只采用定期删除策略，会导致很多key到时间没有删除。于是，惰性删除派上用场。也就是说在你获取某个key的时候，Redis会检查一下，这个key如果设置了过期时间那么是否过期了？如果过期了此时就会删除。</p></li><li><p><strong>采用定期删除+惰性删除就没其他问题了么?</strong></p><p>不是的，如果定期删除没删除key。然后你也没即时去请求key，也就是说惰性删除也没生效。这样，redis的内存会越来越高。那么就应该采用<strong>内存淘汰机制</strong>。<br>在redis.conf中有一行配置</p></li></ul></li></ul><blockquote><p>maxmemory-policy volatile-lru</p></blockquote><ul><li>该配置就是配内存淘汰策略的(什么，你没配过？好好反省一下自己)<ol><li>noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。<strong>应该没人用吧。</strong></li><li>allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。<strong>推荐使用，多数项目在用这种。</strong></li><li>allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。<strong>应该也没人用吧，你不删最少使用Key,去随机删。</strong></li><li>volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。<strong>这种情况一般是把redis既当缓存，又做持久化存储的时候才用。不推荐</strong></li><li>volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。<strong>依然不推荐</strong></li><li>volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。<strong>不推荐</strong><br>ps：如果没有设置 expire 的key, 不满足先决条件(prerequisites); 那么 volatile-lru, volatile-random 和 volatile-ttl 策略的行为, 和 noeviction(不删除) 基本上一致。</li></ol></li></ul><h3 id="6-redis和数据库双写一致性问题（难度大-问得多认真看）"><a href="#6-redis和数据库双写一致性问题（难度大-问得多认真看）" class="headerlink" title="6.redis和数据库双写一致性问题（难度大,问得多认真看）"></a><strong>6.redis和数据库双写一致性问题（难度大,问得多认真看）</strong></h3><p>现在只能保证最终一致性(下面有,就是key过期时间)，没法保证即时一致性,之前我们在项目中使用的流程是这样</p><ol><li><p>查询请求，先看redis中是否有，有就返回，没有就去数据库查询，然后放入redis</p></li><li><p>更新的时候先删除缓存在写入数据库</p></li></ol><p>那么这儿有什么问题呢?</p><ul><li>先第一个问题: <strong>为什么是删除而不是更新缓存</strong>?</li></ul><ol><li><p>如果你是一个写数据库场景比较多，而读数据场景比较少的业务需求，采用这种方案就会导致，数据压根还没读到，缓存就被频繁的更新，浪费性能。</p></li><li><p>如果你写入数据库的值，并不是直接写入缓存的，而是要经过一系列复杂的计算再写入缓存。那么，每次写入数据库后，都再次计算写入缓存的值，无疑是浪费性能的。显然，删除缓存更为适合问题</p></li></ol><ul><li><p>脏数据的可能</p><ul><li>线程A删除缓存</li><li>线程A更新数据库</li><li>线程B查询Redis没有进入数据库查询写入缓存<blockquote><p>注意: 因为这里没有确定线程谁先执行，完全有可能在A删除缓存而还没有更新数据库时，线程B发现缓存中没有就去数据库查询，然后放入缓存，这个时候A在更新数据库，那么现在缓存中放入的就是修改前的数据，脏数据，后面来查询的都时得到脏数据(当然可以给数据设置一个过期时间，这个就是最终一致性问题),好吧其实到这儿大家把上面得问题想通，那么就够了，主要想不到这些问题，数据双写一致性没有百分之百得解决方案只能尽量减少发生得概率.我们的解决方案是这样的:</p><blockquote><p>先更新数据库，在删除缓存</p></blockquote></blockquote></li></ul></li><li><p>问题: 一个请求A做查询操作，一个请求B做更新操作，那么会有如下情形产生</p><ol><li>缓存刚好失效</li><li>请求A查询数据库，得一个旧值</li><li>请求B将新值写入数据库</li><li>请求B删除缓存</li><li>请求A将查到的旧值写入缓存<br>ok，如果发生上述情况，确实是会发生脏数据。</li></ol></li><li><p>然而，发生这种情况的概率又有多少呢？<br>   发生上述情况有一个先天性条件，就是步骤（3）的写数据库操作比步骤（2）的读数据库操作耗时更短，才有可能使得步骤（4）先于步骤（5）。可是，大家想想，数据库的读操作的速度远快于写操作的（不然做读写分离干嘛，做读写分离的意义就是因为读操作比较快，耗资源少），因此步骤（3）耗时比步骤（2）更短，这一情形很难出现。</p></li><li><p>解决问题:<br>首先4步可能失败那么即使不出现上述问题也会是脏数据,关于失败可以采用rabbitmq一直发送，至于rabbitmq如何保证消息百分之传递，在消息队列中学习其次出现上述A线程与B线程的问题,可以采用更新操作的B线程双删也就是做两次删除操作<br>伪代码: B线程    </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">b.updateDbxxxx  b更新数据库</span><br><span class="line">b.delete(redis)   B删除与更新数据相关的redis缓存</span><br><span class="line">b.sleep(xxx)   B睡觉</span><br><span class="line">b.delete(redis)   B再次删除</span><br></pre></td></tr></table></figure></li></ul><p>其中睡觉的时间，根据你自己的业务来确定,比如A需要从数据库查询到数据，然后经过一系列的计算，得到结果写入redis，那么这个时间就是A操作这一系列的时间，这个只能自己的业务不断测试得出时间安全值,那么问题又来了，如果sleep时间长就阻塞了增删改得效率,第二次删除可以起线程，或者用消息队列,当然如果数据库用得是主从复制那么，还需要加入主表到从表得更新时间，再然后第二次删除失败，参考上面得消息队列删除，没有百分之百的方案，希望大家理清除能跟面试官说到这儿已经很秀了，方向是线程安全，操作失败，效率等三方面去跟面试官讨论，当然还可以采用canal中间件订阅mysql得二进制日志binlog(了解)。</p><h3 id="7-如何应对缓存穿透和缓存雪崩问题"><a href="#7-如何应对缓存穿透和缓存雪崩问题" class="headerlink" title="7. 如何应对缓存穿透和缓存雪崩问题"></a><strong>7. 如何应对缓存穿透和缓存雪崩问题</strong></h3><p>   如果有大并发的项目，流量有几百万左右。这两个问题一定要深刻考虑。</p><ul><li><p>缓存穿透</p><blockquote><p>即黑客故意去请求缓存中不存在的数据，导致所有的请求都怼到数据库上，从而数据库连接异常。</p></blockquote></li><li><p>解决方案</p><ol><li><p>利用互斥锁，缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试</p></li><li><p>提供一个能迅速判断请求是否有效的拦截机制，比如，利用布隆过滤器（就说只是了解, 布隆过滤器是一个神奇的数据结构，<strong>可以用来判断一个元素是否在一个集合中</strong>），内部维护一系列合法有效的key。迅速判断出，请求所携带的Key是否合法有效。如果不合法，则直接返回。</p></li><li>另外也有一个更为简单粗暴的方法，如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，value是过期时间,但它的过期时间会很短，最长不超过五分钟。通过这个直接设置的默认值存放到缓存，这样第二次到缓冲中获取就有值了，而不会继续访问数据库，这种办法最简单粗暴！</li></ol></li><li><p>缓存雪崩</p><blockquote><p>即缓存同一时间大面积的失效，这个时候又来了一波请求，结果请求都怼到数据库上，从而导致数据库连接异常。什么redis重启，停电也会造成（采用集群，主从同步等保证安全性）</p></blockquote></li><li><p>解决方案</p><ol><li><p>给缓存的失效时间，加上一个随机值，避免集体失效。</p></li><li><p>使用互斥锁，但是该方案吞吐量明显下降了。</p></li><li><p>双缓存。我们有两个缓存，缓存A和缓存B。缓存A的失效时间为20分钟，缓存B不设失效时间。自己做缓存预热操作。然后细分以下几个小点</p><ul><li><p>从缓存A读数据，有则直接返回</p></li><li><p>A没有数据，直接从B读数据，直接返回，并且异步启动一个更新线程。</p></li><li><p>更新线程同时更新缓存A和缓存B。</p></li></ul></li></ol></li><li><p>缓存预热</p><blockquote><p>缓存预热这个应该是一个比较常见的概念，相信很多小伙伴都应该可以很容易的理解，缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！</p></blockquote></li><li><p>解决思路</p><ol><li><p>直接写个缓存刷新页面，上线时手工操作下；</p></li><li><p>数据量不大，可以在项目启动的时候自动进行加载；</p></li><li><p>定时刷新缓存；</p></li></ol></li></ul><h3 id="8-如何解决redis的并发竞争问题（实例就是商城项目得定时订单删除）"><a href="#8-如何解决redis的并发竞争问题（实例就是商城项目得定时订单删除）" class="headerlink" title="8. 如何解决redis的并发竞争问题（实例就是商城项目得定时订单删除）"></a>8. 如何解决redis的并发竞争问题（实例就是商城项目得定时订单删除）</h3><p>这个问题大致就是，同时有多个子系统去set一个key。这个时候要注意什么呢？基本都是redis集群环境，做了数据分片操作。你一个事务中有涉及到多个key操作的时候，这多个key不一定都存储在同一个redis-server上。因此，<strong>redis的事务机制，十分鸡肋。</strong></p><ul><li>解决方案</li></ul><ol><li><p>如果对这个key操作，<strong>不要求顺序</strong><br>这种情况下，准备一个分布式锁(查看第二个项目实现，必须掌握，考虑问题是死锁)，大家去抢锁，抢到锁就做set操作即可，比较简单。</p></li><li><p>如果对这个key操作，<strong>要求顺序</strong><br>假设有一个key1,系统A需要将key1设置为valueA,系统B需要将key1设置为valueB,系统C需要将key1设置为valueC.<br>期望按照key1的value值按照 valueA–&gt;valueB–&gt;valueC的顺序变化。这种时候我们在数据写入数据库的时候，需要保存一个时间戳。假设时间戳如下</p><blockquote><p>系统A key 1 {valueA  3:00}</p><p>系统B key 1 {valueB  3:05}</p><p>系统C key 1 {valueC  3:10}</p></blockquote><p>那么，假设这会系统B先抢到锁，将key1设置为{valueB 3:05}。接下来系统A抢到锁，发现自己的valueA的时间戳早于缓存中的时间戳，那就不做set操作了。以此类推。</p></li></ol><h3 id="9．Redis持久化（能把大概概念说清楚"><a href="#9．Redis持久化（能把大概概念说清楚" class="headerlink" title="9．Redis持久化（能把大概概念说清楚)"></a>9．Redis持久化（能把大概概念说清楚)</h3><p>Redis提供了两种持久化的方式，分别是RDB（Redis DataBase）和AOF（Append Only File）。</p><ul><li><p>RDB，简而言之，就是在不同的时间点，将redis存储的数据生成快照并存储到磁盘等介质上；</p></li><li><p>AOF，则是换了一个角度来实现持久化，那就是将redis执行过的所有写指令记录下来，在下次redis重新启动时，只要把这些写指令从前到后再重复执行一遍，就可以实现数据恢复了。</p></li></ul><p>其实RDB和AOF两种方式也可以同时使用，在这种情况下，如果redis重启的话，则会优先采用AOF方式来进行数据恢复，这是因为AOF方式的数据恢复完整度更高。如果你没有数据持久化的需求，也完全可以关闭RDB和AOF方式，这样的话，redis将变成一个纯内存数据库，就像memcache一样。 </p><h3 id="10-RDB"><a href="#10-RDB" class="headerlink" title="10. RDB"></a>10. RDB</h3><p>RDB方式，是将redis某一时刻的数据持久化到磁盘中，是一种快照式的持久化方法。</p><p>至于时间可以通过在redis.conf中配置下面得内容</p><blockquote><p>900秒（15分钟）内至少1个key值改变（则进行数据库保存–持久化）<br>300秒（5分钟）内至少10个key值改变（则进行数据库保存–持久化）<br>60秒（1分钟）内至少10000个key值改变（则进行数据库保存–持久化）<br>注释：注释掉“save”这一行配置项就可以让保存数据库功能失效。<br>你也可以通过增加一个只有一个空字符串的配置项（如下面的实例）来去掉前面的“save”配置。<br>save “”  </p></blockquote><p><img src="file:///C:\Users\lsw\AppData\Local\Temp\ksohtml\wps73C2.tmp.jpg" alt="img"> </p><p>Redis在进行数据持久化的过程中，会先将数据写入到一个临时文件中，待持久化过程都结束了，才会用这个临时文件替换上次持久化好的文件。正是这种特性，让我们可以随时来进行备份，因为快照文件总是完整可用的。</p><p>对于RDB方式，redis会单独创建（fork）一个子进程来进行持久化，而主进程是不会进行任何IO操作的，这样就确保了redis极高的性能。</p><p>如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。虽然RDB有不少优点，但它的缺点也是不容忽视的。</p><p>如果你对数据的完整性非常敏感，那么RDB方式就不太适合你，因为即使你每5分钟都持久化一次，当redis故障时，仍然会有近5分钟的数据丢失。所以，Redis还提供了另一种持久化方式，那就是AOF。手动代码实现rdb<br><img src="file:///C:\Users\lsw\AppData\Local\Temp\ksohtml\wps73D2.tmp.jpg" alt="img"> </p><h3 id="11-AOF"><a href="#11-AOF" class="headerlink" title="11. AOF"></a>11. AOF</h3><p>AOF方式是将执行过的写指令记录下来，在数据恢复时按照从前到后的顺序再将指令都执行一遍，就这么简单。</p><p>开启AOF也是在配置文件redis.conf中配置redis.conf中的appendonly yes就可以打开AOF功能:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#appendfsync always</span><br><span class="line">appendfsync everysec</span><br><span class="line">#appendfsync no</span><br></pre></td></tr></table></figure><p>注:Always表示每次操作，everysec表示每秒(一般用这个),no </p><p>默认使用的AOF持久化策略是每秒钟fsync一次（fsync是指把缓存中的写指令记录到磁盘中），因为在这种情况下，redis仍然可以保持很好的处理性能，即使redis故障，也只会丢失最近1秒钟的数据。</p><p>因为采用了追加方式，如果不做任何处理的话，AOF文件会变得越来越大，为此，redis提供了AOF文件重写（rewrite）机制，即当AOF文件的大小超过所设定的阈值时，redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集。举个例子或许更形象，假如我们调用了100次INCR指令，在AOF文件中就要存储100条指令，但这明显是很低效的，完全可以把这100条指令合并成一条SET指令，这就是重写机制的原理。</p><p>在进行AOF重写时，仍然是采用先写临时文件，全部完成后再替换的流程，所以断电、磁盘满等问题都不会影响AOF文件的可用性，这点大家可以放心。</p><p>AOF方式的另一个好处，我们通过一个“场景再现”来说明。某同学在操作redis时，不小心执行了FLUSHALL，导致redis内存中的数据全部被清空了，这是很悲剧的事情。不过这也不是世界末日，只要redis配置了AOF持久化方式，且AOF文件还没有被重写（rewrite），我们就可以用最快的速度暂停redis并编辑AOF文件，将最后一行的FLUSHALL命令删除，然后重启redis，就可以恢复redis的所有数据到FLUSHALL之前的状态了。是不是很神奇，这就是AOF持久化方式的好处之一。但是如果AOF文件已经被重写了，那就无法通过这种方法来恢复数据了。</p><p>虽然优点多多，但AOF方式也同样存在缺陷，比如在同样数据规模的情况下，AOF文件要比RDB文件的体积大。而且，AOF方式的恢复速度也要慢于RDB方式。</p><p>如果你直接执行BGREWRITEAOF命令，那么redis会生成一个全新的AOF文件，其中便包括了可以恢复现有数据的最少的命令集。</p><p>如果运气比较差，AOF文件出现了被写坏的情况，也不必过分担忧，redis并不会贸然加载这个有问题的AOF文件，而是报错退出。这时可以通过以下步骤来修复出错的文件：</p><ol><li><p>备份被写坏的AOF文件</p></li><li><p>运行redis-check-aof –fix进行修复</p></li><li><p>用diff -u来看下两个文件的差异，确认问题点</p></li><li><p>重启redis，加载修复后的AOF文件 </p></li></ol><p><strong>重写</strong>:</p><p>AOF重写的内部运行原理，我们有必要了解一下。</p><p>在重写即将开始之际，redis会创建（fork）一个“重写子进程”，这个子进程会首先读取现有的AOF文件，并将其包含的指令进行分析压缩并写入到一个临时文件中。</p><p>与此同时，主工作进程会将新接收到的写指令一边累积到内存缓冲区中，一边继续写入到原有的AOF文件中，这样做是保证原有的AOF文件的可用性，避免在重写过程中出现意外。</p><p>当“重写子进程”完成重写工作后，它会给父进程发一个信号，父进程收到信号后就会将内存中缓存的写指令追加到新AOF文件中。</p><p>当追加结束后，redis就会用新AOF文件来代替旧AOF文件，之后再有新的写指令，就都会追加到新的AOF文件中了。所以读了那么多:</p><p><strong>RDB和AOF的优缺点</strong></p><ul><li>RDB 优点：全量数据快照，文件小，恢复快</li><li>RDB 缺点：无法保存最近一次快照之后的数据</li><li>AOF 优点：可读性高，适合保存增量数据，数据不易丢失</li><li>AOF 缺点：文件体积大，恢复时间长 </li></ul><p>最终采用得是RDB与AOF的混合持久化</p><h3 id="12-redis主从复制"><a href="#12-redis主从复制" class="headerlink" title="12.redis主从复制"></a><strong>12.redis主从复制</strong></h3><p>​    主从复制, 是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master)，后者称为从节点(slave)；数据的复制是单向的，只能由主节点到从节点</p><p>​    默认情况下，每台Redis服务器都是主节点；且一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点。</p><p><strong>主从复制的作用</strong></p><ol><li><p>数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。</p></li><li><p>故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。</p></li><li><p>负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。</p></li><li><p>高可用基石：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。</p></li></ol><p>配置网上都是教程自己以后去了解，这里不需要去了解，就说是运维配好了的,因为redis跟mysql不同 主从是redis提供的很简单，所以还是关注java代码实现 </p><h3 id="13-什么是Sentinel？"><a href="#13-什么是Sentinel？" class="headerlink" title="13. 什么是Sentinel？"></a><strong>13.</strong> <strong>什么是Sentinel？</strong></h3><p>它是Redis提供的哨兵程序</p><p>哨兵一般是好几个一起站岗，他们共同监视一个Master以及其Slaves。当哨兵看到Master挂掉了，他们就会互相确认有没有看走眼，一旦多数哨兵都说它挂了，那么他们就能得出结论：Master挂了。 </p><p>此时第一个发现的Sentinel会负责进行自动故障迁移，它会立即在Slaves中选出一个担任Master，所有Slaves从属于新Master，所有客户端对Master的操作转而到这台新Master上。</p><p>Sentinel的主要工作如下：</p><ol><li><p>监控（Monitoring）： Sentinel 会不断地检查你的主服务器和从服务器是否运作正常。</p></li><li><p>提醒（Notification）： 当被监控的某个 Redis 服务器出现问题时， Sentinel 可以通过 API 向管理员或者其他应用程序发送通知。</p></li><li><p>自动故障迁移（Automatic failover):  当一个主服务器不能正常工作时， Sentinel 会开始一次自动故障迁移操作， 它会将失效主服务器的其中一个从服务器升级为新的主服务器， 并让失效主服务器的其他从服务器改为复制新的主服务器； 当客户端试图连接失效的主服务器时， 集群也会向客户端返回新主服务器的地址， 使得集群可以使用新主服务器代替失效服务器。</p></li></ol><p>同样也不去花时间配置了，那么主从加哨兵的java代码如下:</p><h3 id="14-Redis事务-了解"><a href="#14-Redis事务-了解" class="headerlink" title="14. Redis事务(了解)"></a>14. Redis事务(了解)</h3><p>在聊redis事务处理之前，要先和大家介绍四个redis指令，即MULTI、EXEC、DISCARD、WATCH。这四个指令构成了redis事务处理的基础。</p><ol><li>MULTI用来组装一个事务；</li><li>EXEC用来执行一个事务；</li><li>DISCARD用来取消一个事务；</li><li>WATCH用来监视一些key，一旦这些key在事务执行之前被改变，则取消事务的执行。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">redis&gt; MULTI //标记事务开始</span><br><span class="line">OK</span><br><span class="line">redis&gt; INCR user_id //多条命令按顺序入队</span><br><span class="line">QUEUED</span><br><span class="line">redis&gt; INCR user_id</span><br><span class="line">QUEUED</span><br><span class="line">redis&gt; INCR user_id</span><br><span class="line">QUEUED</span><br><span class="line">redis&gt; PING</span><br><span class="line">QUEUED</span><br><span class="line">redis&gt; EXEC //执行</span><br><span class="line">1) (integer) 1</span><br><span class="line">2) (integer) 2</span><br><span class="line">3) (integer) 3</span><br><span class="line">4) PONG</span><br></pre></td></tr></table></figure></li></ol><p>在上面的例子中，我们看到了QUEUED的字样，这表示我们在用MULTI组装事务时，每一个命令都会进入到内存队列中缓存起来，如果出现QUEUED则表示我们这个命令成功插入了缓存队列，在将来执行EXEC时，这些被QUEUED的命令都会被组装成一个事务来执行。</p><h3 id="15-如何从海量数据查询某一前缀的key-一亿查20万"><a href="#15-如何从海量数据查询某一前缀的key-一亿查20万" class="headerlink" title="15. 如何从海量数据查询某一前缀的key(一亿查20万)"></a>15. 如何从海量数据查询某一前缀的key(一亿查20万)</h3><p>keys<em> 会返回所有匹配的key,数据量过大的情况下会造成服务卡顿、阻塞服务器,可以用scan命令来代替keys</em><br>命令: SCAN cursor [MATCH pattern] [COUNT count]<br>Cursor:游标</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">redis 127.0.0.1:6379&gt; scan 0</span><br><span class="line">1) &quot;17&quot;      -----第一个值   作为下次的游标</span><br><span class="line">2)  1) &quot;key:12&quot;    </span><br><span class="line">2) &quot;key:8&quot;    </span><br><span class="line">3) &quot;key:4&quot;    </span><br><span class="line">4) &quot;key:14&quot;    </span><br><span class="line">5) &quot;key:16&quot;    </span><br><span class="line">6) &quot;key:17&quot;    </span><br><span class="line">7) &quot;key:15&quot;    </span><br><span class="line">8) &quot;key:10&quot;    </span><br><span class="line">9) &quot;key:3&quot;   </span><br><span class="line">10) &quot;key:7&quot;   </span><br><span class="line">11) &quot;key:1&quot;</span><br><span class="line">redis 127.0.0.1:6379&gt; scan 17</span><br><span class="line">1) &quot;0&quot;</span><br><span class="line">2) 1) &quot;key:5&quot;  </span><br><span class="line">   2) &quot;key:18&quot;   </span><br><span class="line">   3) &quot;key:0&quot;   </span><br><span class="line">   4) &quot;key:2&quot;   </span><br><span class="line">   5) &quot;key:19&quot;   </span><br><span class="line">   6) &quot;key:13&quot;   </span><br><span class="line">   7) &quot;key:6&quot;   </span><br><span class="line">   8) &quot;key:9&quot;   </span><br><span class="line">   9) &quot;key:11&quot;</span><br></pre></td></tr></table></figure><p>SCAN命令的返回值 是一个包含两个元素的数组， 第一个数组元素是用于进行下一次迭代的新游标， 而第二个数组元素则又是一个数组， 这个数组中包含了所有被迭代的元素。</p><p>注意：返回的游标不一定是递增的，可能后一次返回的游标比前一次的小。</p><p>在第二次调用 SCAN 命令时， 命令返回了游标 0 ， 这表示迭代已经结束， 整个数据集已经被完整遍历过了</p><p>SCAN增量式迭代命令并不保证每次执行都返回某个给定数量的元素,甚至可能会返回零个元素， 但只要命令返回的游标不是 0 ， 应用程序就不应该将迭代视作结束 </p><p>Count:</p><p>对于增量式迭代命令不保证每次迭代所返回的元素数量，我们可以使用COUNT选项， 对命令的行为进行一定程度上的调整。COUNT 选项的作用就是让用户告知迭代命令， 在每次迭代中应该从数据集里返回多少元素。使用COUNT 选项对于对增量式迭代命令相当于一种提示， 大多数情况下这种提示都比较有效的控制了返回值的数量。</p><p>注意:COUNT选项并不能严格控制返回的key数量，只能说是一个大致的约束。并非每次迭代都要使用相同的 COUNT 值，用户可以在每次迭代中按自己的需要随意改变 COUNT 值， 只要记得将上次迭代返回的游标用到下次迭代里面就可以了。</p><p>Match:匹配规则</p><p>scan 0 match key1* count 10</p><p>表示从头开始 扫描10个 key为key1开头的key</p><h3 id="16-常用命令：（记常用的，简单好记的）"><a href="#16-常用命令：（记常用的，简单好记的）" class="headerlink" title="16.常用命令：（记常用的，简单好记的）"></a><strong>16.常用命令：（记常用的，简单好记的）</strong></h3><ul><li><p>String:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">set key value  </span><br><span class="line">get key </span><br><span class="line">del key </span><br><span class="line">mset key value [key value...]  --批量设置键值</span><br><span class="line">mget key [key...]  --批量获取键值</span><br><span class="line">incr key </span><br><span class="line">decr key</span><br><span class="line">incrby key increment </span><br><span class="line">decrby key decrement</span><br><span class="line">incrbyfloat key increment</span><br><span class="line">getset key</span><br><span class="line">append key value --如果key值存在则在key后面追加字符，不存在则创建</span><br><span class="line">strlen key</span><br><span class="line">setrange key offset value --设置指定位置字符</span><br><span class="line">getrange key start end --获取部分字符串</span><br></pre></td></tr></table></figure></li><li><p>Hash</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">hset key field value</span><br><span class="line">hsetnx key field value --原key的field不存在则set成功，否则失败</span><br><span class="line">hget key field</span><br><span class="line">hdel key field</span><br><span class="line">hgetall key</span><br><span class="line">hlen key</span><br><span class="line">hmget key  field [field...]</span><br><span class="line">hmset key filed value [field value...]</span><br><span class="line">hkeys key</span><br><span class="line">hvals key</span><br><span class="line">hexists key field</span><br><span class="line">hincrby key field</span><br><span class="line">hincrbyfloat key field</span><br><span class="line">hstrlen key field</span><br></pre></td></tr></table></figure></li><li><p>List</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">lpush key value [value...]</span><br><span class="line">rpush key value [value...]</span><br><span class="line">lpop key </span><br><span class="line">rpop key</span><br><span class="line">lrange key start end</span><br><span class="line">llen key</span><br><span class="line">lset key index value</span><br><span class="line">blpop key [key...] timeout--左侧阻塞式弹出</span><br><span class="line">brpop key [key...] timeout --右侧阻塞式弹出</span><br><span class="line">lindex key index   --获取对应index的value</span><br><span class="line">linsert key before|after pivot value   --在&apos;pivot&apos;这个元素之前(before)或之后(after)插入一个值</span><br><span class="line">lset key index value  </span><br><span class="line">ltrim key start end --按照索引范围剪裁列表 如 ltrim list 1 3  就是保留列表第二到第四个元素</span><br></pre></td></tr></table></figure></li><li><p>Set</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">sadd key element [element...]</span><br><span class="line">srem key element [element...]</span><br><span class="line">smembers key  --查看集合所有的元素</span><br><span class="line">sismember key element --查看元素是否属于该集合</span><br><span class="line">scard key  --查看集合元素数量</span><br><span class="line">srandmember key --随机获取集合中某一个元素</span><br><span class="line">spop key</span><br><span class="line">sinter key [key...]</span><br><span class="line">sdiff key [key...]</span><br><span class="line">sunion key [key...]</span><br><span class="line">sinterstore destination  key [key...]</span><br><span class="line">sdiffstore destination key [key]</span><br><span class="line">sunionstore destination key [key...]</span><br></pre></td></tr></table></figure></li><li><p>Zset</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">zadd key score member [score member]</span><br><span class="line">zrem key member</span><br><span class="line">zcard key</span><br><span class="line">zscore key member</span><br><span class="line">zrank key member</span><br><span class="line">zrevrank key member</span><br><span class="line">zincrby key increment member</span><br><span class="line">zrange key start end [withscores]</span><br><span class="line">zrevrange key start end [withscores]</span><br><span class="line">zrangebyscore key min max [withscores]</span><br><span class="line">zrevrangebyscore key max min [withscores]</span><br><span class="line">zcount key min max   ##所有的min max 支持开区间闭区间，并且 -inf代表无穷小+inf代表无穷大##</span><br><span class="line">zremrangebyscore key min max    ##如 zrangebyscore score:rank  (80 +inf ##</span><br><span class="line">zremrangebyrank key start end   ##代表查找score:rank这个有序集合中大于80分的成员##</span><br><span class="line">zinterstore destination numkeys key [key...]  --这里numkeys表示需要做交集的key的个数</span><br><span class="line">zunionstore destination numkeys key [key...]  --这里numkeys代表需要做并集的key的个数</span><br></pre></td></tr></table></figure></li><li><p>系统命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">keys pattern --查找满足pattern正则表达的key，如 keys * 表示所有的键 </span><br><span class="line">dbsize --redis中所有的键的数量</span><br><span class="line">rename key newkey --对键重命名，若newkey已经存在于redis中则覆盖,并删除原来的key</span><br><span class="line">renamenx key newkey --当newkey不存在时才操作成功</span><br><span class="line">randomkey --随机返回一个key</span><br><span class="line">expire key second --key在second秒之后失效</span><br><span class="line">expireat key timestamp  -- timestamp代表秒级别的时间戳</span><br><span class="line">pexpire key milliseconds --key 在 milliseconds 毫秒后过期</span><br><span class="line">pexpireat key milliseconds-timestamp --key 在 milliseconds-timestamp毫秒级别的时间戳后失效</span><br><span class="line">scan key cusor [match pattern] [COUNT count] </span><br><span class="line">hscan key cusor [match pattern] [COUNT count] --hash类型渐进式遍历</span><br><span class="line">sscan key cusor [match pattern] [COUNT count] --set类型渐进式遍历</span><br><span class="line">zscan key cusor [match pattern] [COUNT count] --sortedSet类型渐进式遍历</span><br><span class="line">select dbIndex --切换数据库</span><br><span class="line">#########迁移键############</span><br><span class="line">move key db --将key迁移到db中去</span><br><span class="line">dump key --将key序列化，RDB格式</span><br><span class="line">resotre key ttl value --将序列化的值复原 ttl代表过期时间，若ttl为0则代表永久有效</span><br></pre></td></tr></table></figure></li></ul><h3 id="17-一致性hash算法"><a href="#17-一致性hash算法" class="headerlink" title="17. 一致性hash算法"></a><strong>17. 一致性hash算法</strong></h3><p>这个讲过不懂得问,记住顺时针与虚拟节点等概念</p><p><img src="file:///C:\Users\lsw\AppData\Local\Temp\ksohtml\wps73F4.tmp.jpg" alt="img"> </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;1-为什么使用Redis&quot;&gt;&lt;a href=&quot;#1-为什么使用Redis&quot; class=&quot;headerlink&quot; title=&quot;1. 为什么使用Redis?&quot;&gt;&lt;/a&gt;1. 为什么使用Redis?&lt;/h3&gt;&lt;p&gt;​    主要是从两个角度去考虑:&lt;strong&gt;性
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2019/02/23/jvm%E9%87%8D%E7%82%B9/"/>
    <id>http://yoursite.com/2019/02/23/jvm重点/</id>
    <published>2019-02-22T16:10:57.757Z</published>
    <updated>2019-02-21T03:12:44.087Z</updated>
    
    <content type="html"><![CDATA[<ol><li><p>java 如何实现平台无关性？</p><ul><li>因为java是先编译为.class文件，而各个平台都有对应的jvm,例如linux有linux的jvm，windows有windows的jvm，jvm会负责将.class文件解释为当前系统对应的机器指令</li></ul></li><li><p>jvm构成？</p><ul><li><p>方法区，堆，java栈，本地方法栈，程序计数器</p></li><li><p>程序计数器：因为线程随时切换，那么程序计数器就时记录该线程运行到哪儿了</p></li><li><p>虚拟机栈：</p><blockquote><ul><li><p>栈帧：  每一个方法从调用开始到执行完成的过程，就对应着一个栈帧在虚拟机栈里面从入栈到出栈的过程，只有栈顶的栈帧是有效的，称为当前栈帧</p></li><li><p>局部变量表:  局部变量表是一组变量值存储空间，用于存放方法参数和方法内部定义的局部变量</p></li><li><p>操作数栈:  虚拟机把操作数栈作为它的工作区——大多数指令都要从这里弹出数据，执行运算，然后把结果压回操作数栈。（也就是说，操作数栈是进行数据运算的地方)</p></li></ul></blockquote></li><li><p>本地方法栈：</p><ul><li>执行native方法的</li></ul></li><li><p>元空间： 存放class对象的信息</p></li><li><p>堆： 大部分创建的对象都放在这里</p></li></ul></li><li><p>java反射？</p><ul><li><p>通过Class累，可以在运行状态中，对任意一个雷，都能够知道这个类的所有属性和方法，对于任意一个对象，都能够调用它的任意一个方法，这种动态获取的信息以及动态调用对象的方法的功能称为java的反射机制</p></li><li><p>常用api：</p><ul><li>getName(): 获取类的完整名字</li><li>getFields(): 获得累的public类型的属性</li><li>getDelaredFields(): 获得类的所有属性</li><li>getMethods(): 获得类的public类型的方法</li><li>getDeclearedMethods(): 获得类的所有方法</li><li>getContrutors(): 获得类的构造方法</li><li>getAnnotation(): 获取所有的注解</li><li>getDellaredAnnotations(): 获取自己声明的注解</li></ul><blockquote><p>注意： 在访问私有属性和私有方法是，需要对访问的私有属性或方法设置setAccessible(true) 使被反射的类一直java的访问检查机制，否则会报IllegalAccessException</p></blockquote></li></ul></li><li><p>类加载器？</p><p>四种类加载器：</p><ul><li>启动类加载器：负责吧JAVA_HOME\LIB目录下的类库加载到虚拟机的内存中，用来加载java的核心库，此类加载器不继承于ClassLoader，不能被java程序直接调用，代码是用C++ 编写的</li><li>扩展类加载器：这个类负载加载JAVA_HOME\LIB/EXT目录下的类库，用来加载java的扩展库，开发者可以直接使用这个类的加载器</li><li>应用程序类加载器：这个类加载器负责加载用户类路径下的类库，一般我们编写的java类都是有这个类加载器加载，这个类加载器是ClasLoader中的个体SYstemClassLoader() 方法的返回值，所以也成为系统类加载器，一般情况下这就是系统默认的类加载器</li><li>自定义类加载器：<ul><li>继承ClassLoader</li><li>重写findClass方法</li><li>调用defineClas() 方法</li></ul></li></ul></li><li><p>双亲委派机制？</p><ul><li><p>保证一个类只被加载一次</p><blockquote><p>如果一个类加载器收到了类加载的请求,它不会自己去尝试加载这个类,而是把这个请求委派给父类加载器去完成,这样层层递进,最终所有的加载请求都被传到最顶层的启动类加载器中,只有当父类加载器无法完成这个加载请求(它的搜索范围内没有找到所需的类)时,才会交给子类加载器去尝试加载.</p></blockquote></li></ul></li><li><p>类的加载方式？</p><ul><li>显示加载：<ul><li>调用ClassLoader.loadClass(className) 与Class.forName(className)</li></ul></li><li>隐式加载：<ul><li>创建类对象</li><li>使用类的静态域</li><li>创建子类对象</li><li>使用子类的静态域</li><li>在JVM启动时，BootStrapLoader会加载一些JVM自身运行所需的class</li><li>在JVM启动时，ExtClassLoader会加载指定目录下一些特殊的class</li><li>在JVM启动时，AppClassLoader会加载classpath路径下的class，以及main函数所在的类的class文件</li></ul></li></ul><p><strong>两种加载class文件到jvm的区别？</strong></p><ul><li>Class.forName(className)加载class的同时会初始化静态域ClassLoader.loadClass(className)则不会初始化静态域（效率高，例如spring为了保证容器的快速初始化就采用这种方式</li></ul></li><li><p>类的装载过程？</p><ul><li><p>类加载时机：</p><ol><li><p>创建类的实例</p></li><li><p>访问类的静态变量(除常量【被final修辞的静态变量】原因:常量一种特殊的变量，因为编译器把他们当作值(value)而不是域(field)来对待。如果你的代码中用到了常变量(constant variable)，编译器并不会生成字节码来从对象中载入域的值，而是直接把这个值插入到字节码中。这是一种很有用的优化，但是如果你需要改变final域的值那么每一块用到那个域的代码都需要重新编译。  static final</p></li><li><p>访问类的静态方法</p></li><li><p>反射如(Class.forName(“my.xyz.Test”))</p></li><li><p>当初始化一个类时，发现其父类还未初始化，则先出发父类的初始化</p></li><li><p>虚拟机启动时，定义了main()方法的那个类先初始化</p></li></ol></li><li><p>加载：</p><blockquote><p>在加载阶段（可以参考java.lang.ClassLoader的loadClass()方法），虚拟机需要完成以下三件事情：</p><p>(1). 通过一个类的全限定名来获取定义此类的二进制字节流（并没有指明要从一个Class文件中获取，可以从其他渠道，譬如：网络、动态生成、数据库等）；</p><p>(2). 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构；</p><p>(3). 在内存中(对于HotSpot虚拟就而言就是方法区)生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口</p></blockquote></li><li><p>验证</p><blockquote><p>验证是连接阶段的第一步，这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全</p></blockquote></li><li><p>准备</p><blockquote><p>准备阶段是正式为类变量(static 成员变量)分配内存并设置类变量初始值（零值）的阶段，这些变量所使用的内存都将在方法区中进行分配。这时候进行内存分配的仅包括类变量，而不包括实例变量，实例变量将会在对象实例化时随着对象一起分配在堆中</p></blockquote></li><li><p>解析</p><blockquote><p>解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行</p></blockquote></li><li><p>初始化</p><blockquote><ol><li><p>子类调用父类的静态变量，子类不会被初始化。只有父类被初始化。对于静态字段，只有直接定义这个字段的类才会被初始化.</p></li><li><p>通过数组定义来引用类，不会触发类的初始化</p></li><li><p>访问类的常量，不会初始化类</p></li></ol></blockquote></li></ul></li><li><p>为什么递归会引起statckoverflow？</p><ul><li>每个方法对应一个栈帧，方法多累栈帧放不下，就会stackoverflow</li></ul></li><li><p>jvm 调优参数，xms,xmx,xss的区别？</p><ul><li><p>-Xss规定了每个线程堆栈的大小。一般情况下256K是足够了。影响了此进程中并发线程数大小。</p></li><li><p>-Xms初始的Heap的大小。</p></li><li><p>-Xmx最大Heap的大小。<br>在很多情况下，-Xms和-Xmx设置成一样的。这么设置，是因为当Heap不够用时，会发生内存抖动，影响程序运行稳定性<br>内存抖动: 内存抖动是指内存频繁地分配和回收，而频繁的gc会导致卡顿，严重时和内存泄漏一样会导致OOM（outofmemory内存溢出)</p></li></ul></li><li><p>堆和栈的区别？</p><ul><li><p>功能不同</p><blockquote><p>栈内存用来存储局部变量和方法调用。</p><p>而堆内存用来存储Java中的对象。无论是成员变量，局部变量，还是类变量，它们指向的对象都存储在堆内存中</p></blockquote></li><li><p>共享性不同</p><blockquote><p>栈内存是线程私有的。</p><p>堆内存是所有线程共有的。</p></blockquote></li><li><p>异常错误不同</p><blockquote><p>如果栈内存或者堆内存不足都会抛出异常。</p><p>栈空间不足：java.lang.StackOverFlowError</p><p>堆空间不足：java.lang.OutOfMemoryError</p></blockquote></li><li><p>空间大小</p><blockquote><p>栈的空间大小远远小于堆的</p></blockquote></li><li><p>垃圾回收</p><ul><li>栈自动释放</li><li>堆需要gc</li></ul></li></ul></li><li><p>对象什么时候被判定为垃圾？</p><ul><li><p>判断对象的引用数量</p><ul><li>任何引用计数为0的对象实例都可以被当做垃圾收集</li><li>优点： 执行效率高，程序执行受影响较小</li><li>缺点： 无法检测出循环引用的情况，导致内存泄露</li></ul></li><li><p>判定的方法</p><blockquote><ol><li>引用计数法:之前说过 不懂得问一下</li></ol><p>在对象头处维护一个counter，每增加一次对该对象的引用计数器自加，如果对该对象的引用失联，则计数器自减。当counter为0时，表明该对象已经被废弃，不处于存活状态。这种方式一方面无法区分软、虛、弱、强引用类别。另一方面，会造成死锁，假设两个对象相互引用始终无法释放counter，永远不能GC</p><p>版权声明：本文为博主原创文章，转载请附上博文链接！可达性分析法：</p><p>选择一个root对象，根据引用</p><ol start="2"><li>可达性分析法:</li></ol><p>通过一系列为GC Roots的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连时，则证明该对象是不可用的。如果对象在进行可行性分析后发现没有与GC Roots相连的引用链，也不会理解死亡。它会暂时被标记上并且进行一次筛选，筛选的条件是是否与必要执行finalize()方法。如果被判定有必要执行finaliza()方法，就会进入F-Queue队列中，并有一个虚拟机自动建立的、低优先级的线程去执行它。稍后GC将对F-Queue中的对象进行第二次小规模标记。如果这时还是没有新的关联出现，那基本上就真的被回收了</p></blockquote></li><li><p>可作为gcRoot的对象：</p><blockquote><p>1.虚拟机栈（栈帧中的本地变量表）中引用的对象；</p><p>2.方法区中的类静态属性引用的对象；</p><p>3.方法区中常量引用的对象；</p><p>4.本地方法栈中JNI（即一般说的Native方法）中引用的对象</p><p>注意:方法区只是一个规范，1.8之前叫永久代，1.8以后叫元空间</p></blockquote></li></ul></li><li><p>垃圾回收算法？</p><ul><li><p>标记清除算法</p><blockquote><p>在标记阶段，collector从mutator根对象开始进行遍历，对从mutator根对象可以访问到的对象都打上一个标识，一般是在对象的header中，将其记录为可达对象。</p><p>而在清除阶段，collector对堆内存(heap memory)从头到尾进行线性的遍历，如果发现某个对象没有标记为可达对象-通过读取对象的header信息，则就将其回收</p><p>缺点:会产生空间碎片化</p></blockquote></li><li><p>复制算法</p><blockquote><p>复制算法将内存划分为两个区间，在任意时间点，所有动态分配的对象都只能分配在其中一个区间（称为活动区间），而另外一个区间（称为空闲区间）则是空闲的。</p><p>​         当有效内存空间耗尽时，JVM将暂停程序运行，开启复制算法GC线程。接下来GC线程会将活动区间内的存活对象，全部复制到空闲区间，且严格按照内存地址依次排列，与此同时，GC线程将更新存活对象的内存引用地址指向新的内存地址。</p><p>​        此时，空闲区间已经与活动区间交换，而垃圾对象现在已经全部留在了原来的活动区间，也就是现在的空闲区间。事实上，在活动区间转换为空间区间的同时，垃圾对象已经被一次性全部回收。</p><p>优点：避免了内存碎片化，空间不连续性</p><p>缺点: 本来挺大一片地方，现在只能用一半，搞得挺不爽的，世界上本来没有免费的饭菜，就算是用空间换取时间吧。</p></blockquote></li><li><p>标记整理算法</p><blockquote></blockquote></li></ul></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol&gt;
&lt;li&gt;&lt;p&gt;java 如何实现平台无关性？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;因为java是先编译为.class文件，而各个平台都有对应的jvm,例如linux有linux的jvm，windows有windows的jvm，jvm会负责将.class文件解释为当前系统对应的机器
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://yoursite.com/2019/02/22/hello-world/"/>
    <id>http://yoursite.com/2019/02/22/hello-world/</id>
    <published>2019-02-22T15:18:16.658Z</published>
    <updated>2019-02-22T15:18:16.658Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
  </entry>
  
</feed>
